{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMOf8AwESazt5CpzhMm2XDG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjg331/Scrape_Youtube_Video_Info-Comments/blob/main/(2023.09)Scrape_Youtube_Video_Info_Comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Soi0eu5ghyk9"
      },
      "outputs": [],
      "source": [
        "# 이 부분은 처음 한번만 실행하면 됌.\n",
        "# 코드 수정 - \"The reason is that the last Ubuntu update update supports chromium driver just via snap.\"\n",
        "# 최근 우분투 업데이트에서 크롬 드라이버 설치를 snap을 이용해서만 하도록 바뀜\n",
        "# 고로 snap 없이 설치하는 아래 우회 코드로 변경\n",
        "# 출처 : https://colab.research.google.com/drive/1cbEvuZOhkouYLda3RqiwtbM-o9hxGLyC\n",
        "# 출처2 : https://stackoverflow.com/questions/75155063/selenium-use-chrome-on-colab-got-unexpectedly-exited\n",
        "\n",
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium chromium-driver\n",
        "\n",
        "# Install selenium\n",
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# -*- coding: UTF-8 -*-\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "#Colab에선 웹브라우저 창이 뜨지 않으므로 별도 설정한다.\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')        # Head-less 설정\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=options)"
      ],
      "metadata": {
        "id": "-Aapsbz0h1AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_page_sources_youtube(url):\n",
        "\n",
        "    browser = driver\n",
        "    page_sources = []\n",
        "\n",
        "    # Move to the page\n",
        "    url = url\n",
        "    browser.get(url)\n",
        "\n",
        "    # Scroll down\n",
        "    last_page_height = browser.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "\n",
        "    # Iterate until end script of the website\n",
        "    while True:\n",
        "\n",
        "        browser.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "        time.sleep(3.0)\n",
        "\n",
        "        new_page_height = browser.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "\n",
        "        if new_page_height == last_page_height:\n",
        "\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Continue\")\n",
        "\n",
        "        last_page_height = new_page_height\n",
        "\n",
        "        print(\"End of scrolling\")\n",
        "\n",
        "        page_source = browser.page_source\n",
        "        page_sources.append(page_source)\n",
        "\n",
        "    return page_sources"
      ],
      "metadata": {
        "id": "PXiTf1b3h1Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_info(url):\n",
        "\n",
        "    url = url\n",
        "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 Edg/117.0.2045.36\"}\n",
        "    res = requests.get(url, headers=headers)\n",
        "    res.raise_for_status()\n",
        "    soup = BeautifulSoup(res.text, \"lxml\")\n",
        "\n",
        "    info = []\n",
        "\n",
        "    video_name = soup.find('meta', itemprop=\"name\")['content']\n",
        "    num_views = soup.find('meta', itemprop=\"interactionCount\")['content']\n",
        "    date_published = soup.find('meta', itemprop=\"datePublished\")['content']\n",
        "\n",
        "    info.append([video_name, num_views, date_published])\n",
        "\n",
        "    video_info = pd.DataFrame(index = [\"Info\"], columns = ['Video_name', 'Num_views', 'Date_published'],\n",
        "                              data = info).transpose()\n",
        "    return video_info\n",
        "\n",
        "def get_Comment_Like(url):\n",
        "\n",
        "    browser = driver\n",
        "    comment = []\n",
        "    comment_date= []\n",
        "    num_like = []\n",
        "\n",
        "    # Move to the page\n",
        "    url = url\n",
        "    browser.get(url)\n",
        "\n",
        "    # Scroll down and wait to get the reply\n",
        "\n",
        "    browser.execute_script(\"window.scrollTo(0, 800);\")\n",
        "    time.sleep(10)\n",
        "    browser.execute_script(\"window.scrollTo(800, 0);\")\n",
        "    time.sleep(5)\n",
        "    browser.execute_script(\"window.scrollTo(10, document.documentElement.scrollHeight);\")\n",
        "    time.sleep(5)\n",
        "\n",
        "    last_page_height = browser.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "\n",
        "    # Iterate until end script of the website\n",
        "    while True:\n",
        "\n",
        "        browser.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "        time.sleep(3.0)\n",
        "\n",
        "        new_page_height = browser.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "\n",
        "        if new_page_height == last_page_height:\n",
        "            print(\"End scrolling\")\n",
        "            print(\"---\"*30)\n",
        "            print(\"Start Scrapping\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Iterating...\")\n",
        "\n",
        "        last_page_height = new_page_height\n",
        "\n",
        "    # Get the comment\n",
        "    for comments in browser.find_elements(By.ID, \"content-text\"):\n",
        "        comment.append(comments.text)\n",
        "\n",
        "    # Get year of the comment(\"~months,weeks,days\" will be 2022 and others will be \"2022 - ~years\" in this code)\n",
        "    for dates in browser.find_elements(By.XPATH, '//*[@id=\"header-author\"]/yt-formatted-string/a'):\n",
        "        comment_date.append(dates.text)\n",
        "\n",
        "    # Get the num of likes\n",
        "    for likes in browser.find_elements(By.ID, \"vote-count-middle\"):\n",
        "\n",
        "        if likes.text:\n",
        "            num_like.append(likes.text)\n",
        "        else:\n",
        "            num_like.append(\"0\")\n",
        "\n",
        "\n",
        "\n",
        "    browser.quit()\n",
        "    # Make the dataframe with scrapped data\n",
        "    video_content = pd.DataFrame({\"Comment\": comment, \"Comment_date\": comment_date, \"Likes\": num_like})\n",
        "    video_content.Comment_date = video_content.Comment_date.apply(change_year)\n",
        "    video_content.Likes = video_content.Likes.apply(convert_str_to_number)\n",
        "\n",
        "    return video_content\n",
        "\n",
        "def convert_str_to_number(x):\n",
        "\n",
        "    total_stars = 0\n",
        "    num_map = {'천': 1000, '만': 10000, 'K':1000, 'M':1000000, 'B':1000000000}\n",
        "\n",
        "    if x.isdigit():\n",
        "        total_stars = int(x)\n",
        "    else:\n",
        "        if len(x) > 1:\n",
        "            total_stars = float(x[:-1]) * num_map.get(x[-1].upper(), 1)\n",
        "\n",
        "    return int(total_stars)\n",
        "\n",
        "def change_year(w):\n",
        "    w = w.strip()\n",
        "    w = re.sub(r\"\\(수정됨\\)\", \" \", w)\n",
        "    w = re.sub(r\"전\", \" \", w)\n",
        "    w = re.sub(r\"1년\", \"2022\", w)\n",
        "    w = re.sub(r\"2년\", \"2021\", w)\n",
        "    w = w.strip()\n",
        "    w = re.sub(\"([0-9]+)([^0-9]+$)\", \"2023\", w) # Change any other period to 2022\n",
        "    return w"
      ],
      "metadata": {
        "id": "tTIokQdPh1EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.youtube.com/watch?v=MQ4Fu5vRXjM&t=38s&ab_channel=%EC%9B%90%EC%8B%A0\"\n",
        "test_info = get_info(url)\n",
        "test_df = get_Comment_Like(url)"
      ],
      "metadata": {
        "id": "Ld7gsNH0h1F_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}